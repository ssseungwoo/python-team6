import os
import json
import pandas as pd
import numpy as np
import joblib
from konlpy.tag import Mecab
from sklearn.metrics import classification_report

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸ“ ê²½ë¡œ ì„¤ì •
test_file = "/Users/sseung/Documents/study/python_class/project_root/data/news_combined.json"
model_path = "/Users/sseung/Documents/study/python_class/project_root/model/news_classifier_allinone.pkl"
output_path = "/Users/sseung/Documents/study/python_class/project_root/data/temp/test/test_result_from_json.csv"

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸ§  ë¶„ë¥˜ê¸° í´ë˜ìŠ¤
class NewsClassifier:
    def __init__(self, model, vectorizer, label_encoder, threshold=0.5):
        self.model = model
        self.vectorizer = vectorizer
        self.label_encoder = label_encoder
        self.threshold = threshold

    def predict(self, text):
        X = self.vectorizer.transform([text])
        probs = self.model.predict_proba(X)[0]
        max_prob = max(probs)
        pred_index = probs.argmax()
        if max_prob < self.threshold:
            return "ê¸°íƒ€"
        return self.label_encoder.inverse_transform([pred_index])[0]

    def predict_proba(self, text):
        X = self.vectorizer.transform([text])
        probs = self.model.predict_proba(X)[0]
        return dict(zip(self.label_encoder.classes_, probs))

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸ“¦ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
print("ğŸ“¦ ëª¨ë¸ ë¡œë“œ ì¤‘...")
classifier = joblib.load(model_path)

# ğŸ”  MeCab ë¡œë”©
print("ğŸ”  MeCab ë¡œë”© ì¤‘...")
mecab = Mecab()

def extract_nouns(text):
    if not isinstance(text, str):
        return []
    return [n for n in mecab.nouns(text) if len(n) > 1]

# ğŸ“‚ í…ŒìŠ¤íŠ¸ì…‹ ë¡œë”©
print("ğŸ“‚ í…ŒìŠ¤íŠ¸ì…‹ ë¡œë“œ ì¤‘...")
test_df = pd.read_json(test_file)

# âœ… ì»¬ëŸ¼ ì´ë¦„ í™•ì¸ ë° ì‚¬ìš©
text_col = "text" if "text" in test_df.columns else "prompt"
test_df["cleaned_title"] = test_df[text_col]
test_df["cleaned_prompt"] = test_df[text_col]

# ğŸ”§ ëª…ì‚¬ ì¶”ì¶œ ë° ê²°í•©
print("ğŸ”§ ëª…ì‚¬ ì¶”ì¶œ ì¤‘...")
test_df["processed_text"] = (test_df["cleaned_title"] + " " + test_df["cleaned_prompt"]).apply(
    lambda x: " ".join(extract_nouns(x))
)

# ğŸ¤– ì˜ˆì¸¡
print("ğŸ¤– ì˜ˆì¸¡ ì¤‘...")
test_df["predicted_topic"] = test_df["processed_text"].apply(classifier.predict)

# ğŸ“Š í‰ê°€
if "topic" in test_df.columns:
    print("\nğŸ“Š í…ŒìŠ¤íŠ¸ì…‹ ë¶„ë¥˜ ì„±ëŠ¥ í‰ê°€:")
    print(classification_report(test_df["topic"], test_df["predicted_topic"]))
else:
    print("\nğŸ” ë¼ë²¨ ì—†ìŒ - ì˜ˆì¸¡ ê²°ê³¼:")
    for i, row in test_df.iterrows():
        print(f"[{i+1}] {row['cleaned_title']} â†’ ì˜ˆì¸¡: {row['predicted_topic']}")

# ğŸ’¾ ê²°ê³¼ ì €ì¥
test_df.to_csv(output_path, index=False)
print(f"\nâœ… ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {output_path}")
