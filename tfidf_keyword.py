import json
import re
from collections import Counter
from classification import predicted_topic, predicted_probability
from crawling import get_crawled_text

# ðŸ”§ ì„¤ì •
idf_path = "/Users/sseung/Documents/study/python_class/project/topic_idf_soynlp_cleaned/ì •ì¹˜/idf_values.json"

# âœ… ìœ íš¨í•œ ëª…ì‚¬ í•„í„°
def is_valid_token(token):
    return bool(re.fullmatch(r"[ê°€-íž£a-zA-Z0-9]{2,}", token))

# âœ… í…ìŠ¤íŠ¸ì—ì„œ ëª…ì‚¬ í›„ë³´ ì¶”ì¶œ
def extract_tokens(text):
    tokens = re.findall(r"[ê°€-íž£a-zA-Z0-9]{2,}", text)
    return [tok for tok in tokens if is_valid_token(tok)]

# âœ… ìž…ë ¥ ë¬¸ìž¥
text = get_crawled_text()
tokens = extract_tokens(text)
token_counts = Counter(tokens)

# âœ… IDF ê°’ ë¶ˆëŸ¬ì˜¤ê¸°
with open(idf_path, "r", encoding="utf-8") as f:
    idf_dict = json.load(f)

# âœ… TF-IDF ê³„ì‚°
tfidf_scores = {}
total_tokens = sum(token_counts.values())

for token, tf in token_counts.items():
    if token in idf_dict:
        idf = idf_dict[token]
        tfidf = (tf / total_tokens) * idf
        tfidf_scores[token] = tfidf

# âœ… 0.5 ì´ìƒ í‚¤ì›Œë“œë§Œ ë¦¬ìŠ¤íŠ¸ë¡œ ì €ìž¥
keywords_above_threshold = [word for word, score in tfidf_scores.items() if score >= 0.05]

# âœ… ê²°ê³¼ ì¶œë ¥
# print("ðŸ“Œ TF-IDF â‰¥ 0.05 í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸:")
# print(keywords_above_threshold)

extracted_keywords = keywords_above_threshold

